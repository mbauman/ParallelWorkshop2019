{
 "cells": [
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Pkg; Pkg.activate(@__DIR__); Pkg.instantiate()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Parallel Algorithms: Thinking in Parallel\n",
    "\n",
    "Now that we're starting to see the challenges of parallelism, it's worth taking\n",
    "a step back and examining how we might go about designing parallel algorithms.\n",
    "\n",
    "This is adapted from a [workshop paper](http://jiahao.github.io/parallel-prefix/) by Jiahao Chen and\n",
    "Alan Edelman entitled \"Parallel Prefix Polymorphism Permits Parallelization, Presentation & Proof\" and\n",
    "will appear in the proceedings of the [First Workshop for High Performance Technical Computing in Dynamic\n",
    "Languages](http://jiahao.github.io/hptcdl-sc14/), held in conjunction with [SC14: The International Conference on High Performance Computing, Networking, Storage and Analysis](http://sc14.supercomputing.org/)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Compose, Gadfly"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# `reduce()`\n",
    "\n",
    "Reduction applies a binary operator to a vector repeatedly to return a scalar. Thus + becomes sum, and * becomes prod.\n",
    "\n",
    "It is considered a basic parallel computing primitive."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "reduce(+, 1:8) == sum(1:8)  # triangular numbers"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "reduce(*, 1:8) == prod(1:8) # factorials"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "You can also use reduce to compute Fibonacci numbers using their recurrences."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "M=[1 1; 1 0]\n",
    "reduce(*,fill(M,3))\n",
    "prod(fill(M,3))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n= 40 # Try changing n to pick different values (try between 0-100)\n",
    "@show prod(fill(big.(M),n))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# `prefix` or `scan`\n",
    "\n",
    "Having discussed `reduce`, we are now ready for the idea behind prefix sum.\n",
    "Prefix or scan or accumulate is long considered an important parallel\n",
    "primitive as well.\n",
    "\n",
    "Suppose you wanted to compute the partial sums of a vector, i.e. given\n",
    "`y[1:n]`, we want to overwrite the vector `y` with the vector of partial sums\n",
    "\n",
    "```julia\n",
    "new_y[1] = y[1]\n",
    "new_y[2] = y[1] + y[2]\n",
    "new_y[3] = y[1] + y[2] + y[3]\n",
    "...\n",
    "```\n",
    "\n",
    "At first blush, it seems impossible to parallelize this, since\n",
    "\n",
    "```julia\n",
    "new_y[1] = y[1]\n",
    "new_y[2] = new_y[1] + y[2]\n",
    "new_y[3] = new_y[2] + y[3]\n",
    "...\n",
    "```\n",
    "\n",
    "which appears to be an intrinsically serial process. As written with a `+`\n",
    "operator, this is `cumsum` — but note that it can generalize to any operation."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function prefix_serial!(⊕, y)\n",
    "    for i=2:length(y)\n",
    "        y[i] = y[i-1] ⊕ y[i]\n",
    "    end\n",
    "    y\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@show prefix_serial!(+, [1:8;])\n",
    "@show cumsum(1:8)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@show prefix_serial!(*, [1:8;])\n",
    "@show cumprod(1:8)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@show accumulate(*, [1:8;])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "However, it turns out that because these operations are associative, we can regroup the _order_ of how these sums or products are carried out. (This of course extends to other associative operations, too.) Another ordering of 8 associative operations is provided by `prefix8!`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Magic :)\n",
    "function prefix8!(⊕, y)\n",
    "    length(y)==8 || error(\"length 8 only\")\n",
    "    for i in (2,4,6,8); y[i] = y[i-1] ⊕ y[i]; end\n",
    "    for i in (  4,  8); y[i] = y[i-2] ⊕ y[i]; end\n",
    "    for i in (      8); y[i] = y[i-4] ⊕ y[i]; end\n",
    "    for i in (    6  ); y[i] = y[i-2] ⊕ y[i]; end\n",
    "    for i in ( 3,5,7 ); y[i] = y[i-1] ⊕ y[i]; end\n",
    "    y\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prefix8!(+, [1:8;]) == cumsum(1:8)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "In fact, this can generalize beyond just length-8 arrays:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# More magic\n",
    "function prefix!(⊕, y)\n",
    "    l=length(y)\n",
    "    k=ceil(Int, log2(l))\n",
    "    @inbounds for j=1:k, i=2^j:2^j:min(l, 2^k)              #\"reduce\"\n",
    "        y[i] = y[i-2^(j-1)] ⊕ y[i]\n",
    "    end\n",
    "    @inbounds for j=(k-1):-1:1, i=3*2^(j-1):2^j:min(l, 2^k) #\"expand\"\n",
    "        y[i] = y[i-2^(j-1)] ⊕ y[i]\n",
    "    end\n",
    "    y\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "-"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A = rand(0:9, 123)\n",
    "prefix!(*, copy(A)) == cumprod(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## What is this magic?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We can visualize the operations with a little bit of trickery. In Julia, arrays are simply types that expose the array protocol. In particular, they need to implement  methods for the generic functions `length`, `getindex` and `setindex!`. The last two are used in indexing operations, since statements\n",
    "\n",
    "    y = A[1]\n",
    "    A[3] = y\n",
    "\n",
    "get desugared to\n",
    "\n",
    "    y = getindex(A, 1)\n",
    "    setindex!(A, y, 3)\n",
    "\n",
    "respectively.\n",
    "\n",
    "We can trace through the iterable by introduce a dummy array type, `AccessArray`, which records every access to `getindex` and `setindex!`.\n",
    "\n",
    "Specifically:\n",
    "\n",
    "- `length(A::AccessArray)` returns the length of the array it wraps\n",
    "- `getindex(A::AccessArray, i)` records read access to the index `i` in the `A.read` field and then actually retuns the value in the array it wraps.\n",
    "- `setindex!(A::AccessArray, x, i)` records write access to the index `i`. The `A.history` field is appended with a new tuple consisting of the current `A.read` field and the index `i`, and then it performs the assignment.\n",
    "\n",
    "The way `AccessArray` works, it assumes an association between a single `setindex!` call and and all the preceding `getindex` calls since the previous `setindex!` call, which is sufficient for the purposes of tracing through prefix calls."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mutable struct AccessArray{T,N,A}\n",
    "    data :: A\n",
    "    read :: Vector{Int}\n",
    "    history :: Vector{Tuple{Vector{Int},Int}}\n",
    "end\n",
    "AccessArray(A) = AccessArray{eltype(A), ndims(A), typeof(A)}(A, Int[], Int[])\n",
    "\n",
    "Base.length(A::AccessArray) = length(A.data)\n",
    "\n",
    "function Base.getindex(A::AccessArray, i::Int)\n",
    "    push!(A.read, i)\n",
    "    A.data[i]\n",
    "end\n",
    "\n",
    "function Base.setindex!(A::AccessArray, x, i::Int)\n",
    "    push!(A.history, (A.read, i))\n",
    "    A.read = Int[]\n",
    "    A.data[i] = x\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "M = AccessArray(rand(8))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "M[7] = M[3] + M[2]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "M.history"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "So now we can trace the access pattern when calling `prefix8`!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A=prefix8!(+, AccessArray(rand(8)))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A.history"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Now let's visualize this! Each entry in `A.history` is rendered by a gate object:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Compose: circle, mm"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct Gate{I,O}\n",
    "    ins :: I\n",
    "    outs :: O\n",
    "end\n",
    "\n",
    "import Gadfly.render\n",
    "\n",
    "function render(G::Gate, x₁, y₁, y₀; rᵢ=0.1, rₒ=0.25)\n",
    "    ipoints = [(i, y₀+rᵢ) for i in G.ins]\n",
    "    opoints = [(i, y₀+0.5) for i in G.outs]\n",
    "    igates  = [circle(i..., rᵢ) for i in ipoints]\n",
    "    ogates  = [circle(i..., rₒ) for i in opoints]\n",
    "    lines = [line([i, j]) for i in ipoints, j in opoints]\n",
    "    compose(context(units=UnitBox(0.5,0,x₁,y₁+1)),\n",
    "    compose(context(), stroke(colorant\"black\"), fill(colorant\"white\"),\n",
    "            igates..., ogates...),\n",
    "    compose(context(), linewidth(0.3mm), stroke(colorant\"black\"),\n",
    "            lines...))\n",
    "end\n",
    "\n",
    "A=Gate([1,2],2)\n",
    "render(A,2,0,0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Now we render the whole algorithm. We have to scan through the trace twice; the first time merely calculates the maximum depth that needs to be drawn and the second time actually generates the objects."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function render(A::AccessArray)\n",
    "    #Scan to find maximum depth\n",
    "    olast = depth = 0\n",
    "    for y in A.history\n",
    "        (any(y[1] .≤ olast)) && (depth += 1)\n",
    "        olast = maximum(y[2])\n",
    "    end\n",
    "    maxdepth = depth\n",
    "\n",
    "    olast = depth = 0\n",
    "    C = []\n",
    "    for y in A.history\n",
    "        (any(y[1] .≤ olast)) && (depth += 1)\n",
    "        push!(C, render(Gate(y...), length(A), maxdepth, depth))\n",
    "        olast = maximum(y[2])\n",
    "    end\n",
    "\n",
    "    push!(C, compose(context(units=UnitBox(0.5,0,length(A),1)),\n",
    "      [line([(i,0), (i,1)]) for i=1:length(A)]...,\n",
    "    linewidth(0.1mm), stroke(colorant\"grey\")))\n",
    "    compose(context(), C...)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "render(prefix!(+, AccessArray(zeros(8))))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Now we can see that `prefix!` rearranges the operations to form two spanning trees:\n",
    "Try changing the number of elements!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "render(prefix!(+, AccessArray(zeros(16))))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "as contrasted with the serial code:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "render(prefix_serial!(+, AccessArray(zeros(8))))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Now exploit the parallelism in the _algorithm_ to use a parallel _implementation_"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using .Threads\n",
    "function prefix_threads!(⊕, y)\n",
    "    l=length(y)\n",
    "    k=ceil(Int, log2(l))\n",
    "    for j=1:k\n",
    "        @threads for i=2^j:2^j:min(l, 2^k)       #\"reduce\"\n",
    "            @inbounds y[i] = y[i-2^(j-1)] ⊕ y[i]\n",
    "        end\n",
    "    end\n",
    "    for j=(k-1):-1:1\n",
    "        @threads for i=3*2^(j-1):2^j:min(l, 2^k) #\"expand\"\n",
    "            @inbounds y[i] = y[i-2^(j-1)] ⊕ y[i]\n",
    "        end\n",
    "    end\n",
    "    y\n",
    "end\n",
    "\n",
    "A = rand(500_000);\n",
    "\n",
    "using BenchmarkTools\n",
    "@btime prefix_serial!(+, $(copy(A)));\n",
    "@btime prefix!(+, $(copy(A)));\n",
    "@btime prefix_threads!(+, $(copy(A)));\n",
    "\n",
    "prefix_threads!(+, copy(A)) == prefix!(+, copy(A)) ≈ cumsum(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Thinking in parallel\n",
    "\n",
    "Notice how we didn't need to contort ourselves in making our algorithm\n",
    "work with `@threads`. We really did _just_ take a `@threads` on it and it\n",
    "just worked. It was both accurate _and_ fast.\n",
    "\n",
    "Coming up with rearrangements that make your particular algorithm parallel\n",
    "friendly isn't always easy, but when possible it makes everything else\n",
    "just fall out naturally.\n",
    "\n",
    "Finally, note that there can be clever ways to visualize algorithms as sanity checks."
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.2-pre.0"
  },
  "kernelspec": {
   "name": "julia-1.1",
   "display_name": "Julia 1.1.2-pre.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
